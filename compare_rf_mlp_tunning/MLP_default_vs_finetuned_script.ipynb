{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pEgWM1po0qVS"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "#run the default model\n",
        "mlp_default = MLPClassifier(random_state=42)\n",
        "mlp_default.fit(x_train, y_train)\n",
        "y_pred_default = mlp_default.predict(x_test)\n",
        "\n",
        "#run the fine-tuned model\n",
        "mlp_tuned = MLPClassifier(random_state=42, hidden_layer_sizes=(100,), max_iter=200, activation= 'relu', solver='lbfgs' )\n",
        "mlp_tuned.fit(x_train, y_train)\n",
        "y_pred_tuned = mlp_tuned.predict(x_test)\n",
        "\n",
        "#estimating the error, f1-score(weighted) and the diff between models\n",
        "error_default = 1 - accuracy_score(y_test, y_pred_default)\n",
        "f1_default = f1_score(y_test, y_pred_default, average='weighted')\n",
        "\n",
        "error_tuned = 1 - accuracy_score(y_test, y_pred_tuned)\n",
        "f1_tuned = f1_score(y_test, y_pred_tuned, average='weighted')\n",
        "\n",
        "delta_error = error_default - error_tuned\n",
        "delta_f1 = f1_tuned - f1_default\n",
        "\n",
        "#PLOT\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 6))\n",
        "\n",
        "\n",
        "#Visual range for y-axis (in order to compare the heights of bars)\n",
        "min_error = min(error_default, error_tuned)\n",
        "max_error = max(error_default, error_tuned)\n",
        "margin_error = 0.01\n",
        "ax1_ylim = (min_error - margin_error, max_error + margin_error)\n",
        "\n",
        "# same for the right plot\n",
        "min_f1 = min(f1_default, f1_tuned)\n",
        "max_f1 = max(f1_default, f1_tuned)\n",
        "margin_f1 = 0.01\n",
        "ax2_ylim = (min_f1 - margin_f1, max_f1 + margin_f1)\n",
        "\n",
        "#left graph\n",
        "ax1.bar(['default', 'fine-tuned'], [error_default, error_tuned], color=['grey', 'skyblue'])\n",
        "ax1.set_title(\"Test Error\", fontsize=13)\n",
        "ax1.set_ylim(ax1_ylim)\n",
        "ax1.set_ylabel('(1 - Accuracy)')\n",
        "ax1.grid(True, axis='y')\n",
        "ax1.text(0.98, 0.95, \"(The lower, the better)\", transform=ax1.transAxes,\n",
        "         fontsize=9, ha='right', va='top', style='italic')\n",
        "ax1.text(0.5, -0.15, f\"Δ Test Error = {delta_error:.3f}\", ha='center',\n",
        "         fontsize=11, fontweight='bold', transform=ax1.transAxes)\n",
        "\n",
        "#right graph\n",
        "ax2.bar(['default', 'fine-tuned'], [f1_default, f1_tuned], color=['grey', 'skyblue'])\n",
        "ax2.set_title(\"Weighted F1-score\", fontsize=13)\n",
        "ax2.set_ylim(ax2_ylim)\n",
        "ax2.set_ylabel('F1-score')\n",
        "ax2.grid(True, axis='y')\n",
        "ax2.text(0.98, 0.95, \"(The higher, the better)\", transform=ax2.transAxes,\n",
        "         fontsize=9, ha='right', va='top', style='italic')\n",
        "ax2.text(0.5, -0.15, f\"Δ F1-score = {delta_f1:.3f}\", ha='center',\n",
        "         fontsize=11, fontweight='bold', transform=ax2.transAxes)\n",
        "\n",
        "fig.suptitle(\"Performance comparison: default MLP vs fine-tuned MLP\", fontsize=14)\n",
        "\n",
        "plt.tight_layout(rect=[0, 0.1, 1, 0.95])\n",
        "\n",
        "plt.savefig(r'C:\\Users\\nolev\\Desktop\\M1 Econometrics\\Machine Learning\\Outputs\\grading_criterion_2.2_mlp.png', dpi=300, bbox_inches='tight')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting"
      ],
      "metadata": {
        "id": "7WWGNZ2p1q7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 6))\n",
        "\n",
        "\n",
        "#Visual range for y-axis (in order to compare the heights of bars)\n",
        "min_error = min(error_default, error_tuned)\n",
        "max_error = max(error_default, error_tuned)\n",
        "margin_error = 0.01\n",
        "ax1_ylim = (min_error - margin_error, max_error + margin_error)\n",
        "\n",
        "# same for the right plot\n",
        "min_f1 = min(f1_default, f1_tuned)\n",
        "max_f1 = max(f1_default, f1_tuned)\n",
        "margin_f1 = 0.01\n",
        "ax2_ylim = (min_f1 - margin_f1, max_f1 + margin_f1)\n",
        "\n",
        "#left graph\n",
        "ax1.bar(['default', 'fine-tuned'], [error_default, error_tuned], color=['grey', 'skyblue'])\n",
        "ax1.set_title(\"Test Error\", fontsize=13)\n",
        "ax1.set_ylim(ax1_ylim)\n",
        "ax1.set_ylabel('(1 - Accuracy)')\n",
        "ax1.grid(True, axis='y')\n",
        "ax1.text(0.98, 0.95, \"(The lower, the better)\", transform=ax1.transAxes,\n",
        "         fontsize=9, ha='right', va='top', style='italic')\n",
        "ax1.text(0.5, -0.15, f\"Δ Test Error = {delta_error:.3f}\", ha='center',\n",
        "         fontsize=11, fontweight='bold', transform=ax1.transAxes)\n",
        "\n",
        "#right graph\n",
        "ax2.bar(['default', 'fine-tuned'], [f1_default, f1_tuned], color=['grey', 'skyblue'])\n",
        "ax2.set_title(\"Weighted F1-score\", fontsize=13)\n",
        "ax2.set_ylim(ax2_ylim)\n",
        "ax2.set_ylabel('F1-score')\n",
        "ax2.grid(True, axis='y')\n",
        "ax2.text(0.98, 0.95, \"(The higher, the better)\", transform=ax2.transAxes,\n",
        "         fontsize=9, ha='right', va='top', style='italic')\n",
        "ax2.text(0.5, -0.15, f\"Δ F1-score = {delta_f1:.3f}\", ha='center',\n",
        "         fontsize=11, fontweight='bold', transform=ax2.transAxes)\n",
        "\n",
        "fig.suptitle(\"Performance comparison: default MLP vs fine-tuned MLP\", fontsize=14)\n",
        "\n",
        "plt.tight_layout(rect=[0, 0.1, 1, 0.95])\n",
        "\n",
        "plt.savefig(r'C:\\Users\\nolev\\Desktop\\M1 Econometrics\\Machine Learning\\Outputs\\grading_criterion_2.2_mlp.png', dpi=300, bbox_inches='tight')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "K5C1j8CN1p8C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}