{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9ed9YPC2Q0V"
      },
      "outputs": [],
      "source": [
        "from ensurepip import bootstrap\n",
        "import pandas as pd\n",
        "import time\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "\n",
        "tweet_bow = pd.read_csv(r\"C:\\Users\\aubin\\OneDrive - Aix-Marseille Université\\AIX EN PROVENCE\\MASTER 1 ECONOMETRIE STATISTIQUE\\S2\\Machine_Learning\\projet_final\\data\\tweets_bow (1).csv\")\n",
        "\n",
        "\n",
        "tweet_bow['label'] = tweet_bow['label'].apply(lambda x: 0 if x == 0 else 1)\n",
        "\n",
        "\n",
        "X = tweet_bow.drop(columns=['label'])\n",
        "y = tweet_bow['label']\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    stratify=y,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "def evaluer_modele(nom, modele, X_train, y_train, X_test, y_test, hyperparams):\n",
        "    start = time.time()\n",
        "    modele.fit(X_train, y_train)\n",
        "    end = time.time()\n",
        "\n",
        "    y_pred = modele.predict(X_test)\n",
        "\n",
        "    print(f\"\\n=== Résultats pour {nom} ===\")\n",
        "    print(\"Classification Report :\\n\", classification_report(y_test, y_pred, digits=4))\n",
        "    print(\"Temps d'entraînement :\", round(end - start, 2), \"secondes\")\n",
        "    print(\"Hyperparamètres :\", hyperparams)\n",
        "\n",
        "    return {\n",
        "        \"Modèle\": nom,\n",
        "        \"Précision\": round(precision_score(y_test, y_pred), 4),\n",
        "        \"Rappel\": round(recall_score(y_test, y_pred), 4),\n",
        "        \"F1-score pondéré\": round(f1_score(y_test, y_pred, average='weighted'), 4),\n",
        "        \"Accuracy\": round(accuracy_score(y_test, y_pred), 4),\n",
        "        \"Temps entraînement (s)\": round(end - start, 2),\n",
        "        \"Hyperparamètres\": hyperparams\n",
        "    }\n",
        "\n",
        "\n",
        "rf_model = RandomForestClassifier(n_estimators=100, max_depth=None, random_state=42)\n",
        "\n",
        "\n",
        "resultats = []\n",
        "\n",
        "\n",
        "resultats.append(evaluer_modele(\n",
        "    \"Random Forest\",\n",
        "    rf_model,\n",
        "    X_train, y_train, X_test, y_test,\n",
        "    \"n_estimators=100, max_depth=None, criterion='gini'\"\n",
        "))\n",
        "\n",
        "\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2],\n",
        "    'bootstrap': [True],\n",
        "    'class_weight':[None,'balanced']\n",
        "}\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "grid_rf = GridSearchCV(\n",
        "    estimator = RandomForestClassifier(random_state=42), param_grid=param_grid_rf,\n",
        "    scoring='f1_weighted',\n",
        "    cv=5,\n",
        "    verbose=2,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_rf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "print(\" Meilleurs hyperparamètres trouvés :\")\n",
        "print(grid_rf.best_params_)\n",
        "\n",
        "print(\"\\n Score moyen (F1 pondéré) sur validation croisée :\")\n",
        "print(round(grid_rf.best_score_, 4))\n",
        "\n",
        "\n",
        "best_rf = grid_rf.best_estimator_\n",
        "y_pred_rf_opt = best_rf.predict(X_test)\n",
        "\n",
        "print(\"\\n Évaluation finale sur test set (modèle optimisé) :\")\n",
        "print(classification_report(y_test, y_pred_rf_opt, digits=4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparison"
      ],
      "metadata": {
        "id": "XGSUkLsI3fFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# run the default model rf\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "y_pred = rf_model.predict(X_test)\n",
        "print(\"Classification Report :\\n\", classification_report(y_test, y_pred, digits=4))\n",
        "\n",
        "\n",
        "# run the fine-tuned model rf\n",
        "rf_tuned = RandomForestClassifier(\n",
        "    bootstrap=True,\n",
        "    random_state=42,\n",
        "    n_estimators=200,\n",
        "    class_weight='balanced',\n",
        "    max_depth=None,\n",
        "    min_samples_leaf=1,\n",
        "    min_samples_split=5\n",
        ")\n",
        "rf_tuned.fit(X_train, y_train)\n",
        "y_pred_rf_tuned = rf_tuned.predict(X_test)\n",
        "print(\"Classification Report :\\n\", classification_report(y_test, y_pred_rf_tuned, digits=4))\n",
        "\n",
        "\n",
        "\n",
        "# estimating the error, f1-score(weighted) and the diff betwenn models\n",
        "error = 1-accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "error_tuned = 1-accuracy_score(y_test, y_pred_rf_tuned)\n",
        "f1_score_tuned = f1_score(y_test, y_pred_rf_tuned, average='weighted')\n",
        "delta_error = error - error_tuned\n",
        "delta_f1 = f1_score_tuned - f1"
      ],
      "metadata": {
        "id": "pB8l50kX21eJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting"
      ],
      "metadata": {
        "id": "T69ueXZF3g75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax1,ax2) = plt.subplots(1,2,figsize=(12, 5))\n",
        "\n",
        "ax1.bar(['RF', 'RF_tuned'],[error,error_tuned], color=['gray','green'])\n",
        "ax1.set_title('Difference betwenn errors of Random Forest model')\n",
        "ax1.set_ylim(0.1075,0.1175)\n",
        "ax1.set_ylabel('Error')\n",
        "ax1.grid(axis='y',linestyle='dotted', alpha=0.4)\n",
        "ax1.text(0.5, -0.15, f\"Δ Test Error = {delta_error:.3f}\", ha='center',\n",
        "         fontsize=11, fontweight='bold', transform=ax1.transAxes)\n",
        "\n",
        "ax2.bar(['RF','RF_tuned'],[f1,f1_score_tuned], color=['gray','green'])\n",
        "ax2.set_title('Difference of average f1-score of Random Forest model')\n",
        "ax2.set_ylabel('f1_score')\n",
        "ax2.set_ylim(0.8775,0.885)\n",
        "ax2.grid(axis='y',linestyle='dotted', alpha=0.4)\n",
        "ax2.text(0.5, -0.15, f\"Δ F1-score = {delta_f1:.3f}\", ha='center',\n",
        "         fontsize=11, fontweight='bold', transform=ax2.transAxes)\n",
        "\n",
        "plt.suptitle('Comparison of the performance of the Random Forest model', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.savefig(r\"C:\\Users\\aubin\\OneDrive - Aix-Marseille Université\\AIX EN PROVENCE\\MASTER 1 ECONOMETRIE STATISTIQUE\\S2\\Machine_Learning\\projet_final\\output\\grading_criterion_2.2_rf.png\", dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "D_szzaYs25q6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}